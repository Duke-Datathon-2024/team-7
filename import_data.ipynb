{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install azure-storage-blob"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: azure-storage-blob in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (12.13.0)\nRequirement already satisfied: azure-core<2.0.0,>=1.23.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-storage-blob) (1.26.4)\nRequirement already satisfied: cryptography>=2.1.4 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-storage-blob) (38.0.4)\nRequirement already satisfied: msrest>=0.6.21 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-storage-blob) (0.7.1)\nRequirement already satisfied: requests>=2.18.4 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-core<2.0.0,>=1.23.1->azure-storage-blob) (2.31.0)\nRequirement already satisfied: typing-extensions>=4.3.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-core<2.0.0,>=1.23.1->azure-storage-blob) (4.6.0)\nRequirement already satisfied: six>=1.11.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-core<2.0.0,>=1.23.1->azure-storage-blob) (1.16.0)\nRequirement already satisfied: cffi>=1.12 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from cryptography>=2.1.4->azure-storage-blob) (1.15.1)\nRequirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from msrest>=0.6.21->azure-storage-blob) (2022.9.24)\nRequirement already satisfied: isodate>=0.6.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from msrest>=0.6.21->azure-storage-blob) (0.6.1)\nRequirement already satisfied: requests-oauthlib>=0.5.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from msrest>=0.6.21->azure-storage-blob) (1.3.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.23.1->azure-storage-blob) (3.1.0)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.23.1->azure-storage-blob) (1.26.16)\nRequirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.23.1->azure-storage-blob) (3.4)\nRequirement already satisfied: pycparser in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob) (2.21)\nRequirement already satisfied: oauthlib>=3.0.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.21->azure-storage-blob) (3.2.2)\n"
        }
      ],
      "execution_count": 1,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.storage.blob import BlobServiceClient\n",
        "import io\n",
        "import pandas as pd\n",
        "\n",
        "# Set up the Azure Blob Storage connections\n",
        "sas_token = \"?sv=2022-11-02&ss=bfqt&srt=sco&sp=rwdlacupiytfx&se=2024-05-13T13:01:11Z&st=2024-04-13T05:01:11Z&spr=https,http&sig=X362UUEwAfkGDCBr2G0ZOc2SX%2FLg9LOddGvPHZ%2Fff00%3D\"\n",
        "\n",
        "datasets = {\n",
        "    \"admission\": {\n",
        "        \"account_url\": \"https://sadukedatauseprod.blob.core.windows.net\",\n",
        "        \"container_name\": \"mimiciv\",\n",
        "        \"blob_name\": \"mimiciv/hosp/admissions.csv\"\n",
        "    },\n",
        "    \"d_items\": {\n",
        "        \"account_url\": \"https://sadukedatauseprod.blob.core.windows.net\",\n",
        "        \"container_name\": \"mimiciv\",\n",
        "        \"blob_name\": \"mimiciv/icu/d_items.csv\"\n",
        "    },\n",
        "    \"chartevents\": {\n",
        "        \"account_url\": \"https://sadukedatauseprod.blob.core.windows.net\",\n",
        "        \"container_name\": \"mimiciv\",\n",
        "        \"blob_name\": \"mimiciv/icu/chartevents.csv\"\n",
        "    }\n",
        "    # \"MIMIC-III\": {\n",
        "    #     \"account_url\": \"https://sadukedatauseprod.blob.core.windows.net\",\n",
        "    #     \"container_name\": \"mimiciii\",\n",
        "    #     \"blob_name\": \"ADMISSIONS.csv\"\n",
        "    # },\n",
        "    # \"eICU-CRD\": {\n",
        "    #     \"account_url\": \"https://sadukedatauseprod.blob.core.windows.net\",\n",
        "    #     \"container_name\": \"eicucrd\",\n",
        "    #     \"blob_name\": \"patient.csv\"\n",
        "    #}\n",
        "}\n",
        "\n",
        "dfs = dict()\n",
        "for dataset_name, dataset_config in datasets.items():\n",
        "    print(f\"Accessing {dataset_name} dataset:\")\n",
        "\n",
        "    # Create a BlobServiceClient using the account URL and SAS token\n",
        "    blob_service_client = BlobServiceClient(\n",
        "        account_url=dataset_config[\"account_url\"],\n",
        "        credential=sas_token\n",
        "    )\n",
        "\n",
        "    # Get a reference to the container\n",
        "    container_client = blob_service_client.get_container_client(dataset_config[\"container_name\"])\n",
        "\n",
        "    # List the blobs in the container\n",
        "    print(f\"Blobs in the {dataset_name} container:\")\n",
        "    for blob in container_client.list_blobs():\n",
        "        print(blob.name)\n",
        "\n",
        "    # Read data from a specific blob (CSV file)\n",
        "    blob_client = container_client.get_blob_client(dataset_config[\"blob_name\"])\n",
        "\n",
        "    # Download the blob content as text\n",
        "    blob_content = blob_client.download_blob().readall().decode(\"utf-8\")\n",
        "\n",
        "    # Process the CSV data using pandas\n",
        "    df = pd.read_csv(io.StringIO(blob_content))\n",
        "    dfs[dataset_name]=df\n",
        "    print(f\"{dataset_name} DataFrame head:\")\n",
        "    print(df.head())\n",
        "\n",
        "    print(\"---\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Accessing admission dataset:\nBlobs in the admission container:\nmimiciv/hosp/admissions.csv\nmimiciv/hosp/d_hcpcs.csv\nmimiciv/hosp/d_icd_diagnoses.csv\nmimiciv/hosp/d_icd_procedures.csv\nmimiciv/hosp/d_labitems.csv\nmimiciv/hosp/diagnoses_icd.csv\nmimiciv/hosp/drgcodes.csv\nmimiciv/hosp/emar.csv\nmimiciv/hosp/emar_detail.csv\nmimiciv/hosp/hcpcsevents.csv\nmimiciv/hosp/labevents.csv\nmimiciv/hosp/microbiologyevents.csv\nmimiciv/hosp/omr.csv\nmimiciv/hosp/patients.csv\nmimiciv/hosp/pharmacy.csv\nmimiciv/hosp/poe.csv\nmimiciv/hosp/poe_detail.csv\nmimiciv/hosp/prescriptions.csv\nmimiciv/hosp/procedures_icd.csv\nmimiciv/hosp/provider.csv\nmimiciv/hosp/services.csv\nmimiciv/hosp/transfers.csv\nmimiciv/icu/caregiver.csv\nmimiciv/icu/chartevents.csv\nmimiciv/icu/d_items.csv\nmimiciv/icu/datetimeevents.csv\nmimiciv/icu/icustays.csv\nmimiciv/icu/ingredientevents.csv\nmimiciv/icu/inputevents.csv\nmimiciv/icu/outputevents.csv\nmimiciv/icu/procedureevents.csv\nadmission DataFrame head:\n   subject_id   hadm_id            admittime            dischtime deathtime  \\\n0    10000032  22595853  2180-05-06 22:23:00  2180-05-07 17:15:00       NaN   \n1    10000032  22841357  2180-06-26 18:27:00  2180-06-27 18:49:00       NaN   \n2    10000032  25742920  2180-08-05 23:44:00  2180-08-07 17:50:00       NaN   \n3    10000032  29079034  2180-07-23 12:35:00  2180-07-25 17:55:00       NaN   \n4    10000068  25022803  2160-03-03 23:16:00  2160-03-04 06:26:00       NaN   \n\n   admission_type admit_provider_id      admission_location  \\\n0          URGENT            P874LG  TRANSFER FROM HOSPITAL   \n1        EW EMER.            P09Q6Y          EMERGENCY ROOM   \n2        EW EMER.            P60CC5          EMERGENCY ROOM   \n3        EW EMER.            P30KEH          EMERGENCY ROOM   \n4  EU OBSERVATION            P51VDL          EMERGENCY ROOM   \n\n  discharge_location insurance language marital_status   race  \\\n0               HOME     Other  ENGLISH        WIDOWED  WHITE   \n1               HOME  Medicaid  ENGLISH        WIDOWED  WHITE   \n2            HOSPICE  Medicaid  ENGLISH        WIDOWED  WHITE   \n3               HOME  Medicaid  ENGLISH        WIDOWED  WHITE   \n4                NaN     Other  ENGLISH         SINGLE  WHITE   \n\n             edregtime            edouttime  hospital_expire_flag  \n0  2180-05-06 19:17:00  2180-05-06 23:30:00                     0  \n1  2180-06-26 15:54:00  2180-06-26 21:31:00                     0  \n2  2180-08-05 20:58:00  2180-08-06 01:44:00                     0  \n3  2180-07-23 05:54:00  2180-07-23 14:00:00                     0  \n4  2160-03-03 21:55:00  2160-03-04 06:26:00                     0  \n---\nAccessing d_items dataset:\nBlobs in the d_items container:\nmimiciv/hosp/admissions.csv\nmimiciv/hosp/d_hcpcs.csv\nmimiciv/hosp/d_icd_diagnoses.csv\nmimiciv/hosp/d_icd_procedures.csv\nmimiciv/hosp/d_labitems.csv\nmimiciv/hosp/diagnoses_icd.csv\nmimiciv/hosp/drgcodes.csv\nmimiciv/hosp/emar.csv\nmimiciv/hosp/emar_detail.csv\nmimiciv/hosp/hcpcsevents.csv\nmimiciv/hosp/labevents.csv\nmimiciv/hosp/microbiologyevents.csv\nmimiciv/hosp/omr.csv\nmimiciv/hosp/patients.csv\nmimiciv/hosp/pharmacy.csv\nmimiciv/hosp/poe.csv\nmimiciv/hosp/poe_detail.csv\nmimiciv/hosp/prescriptions.csv\nmimiciv/hosp/procedures_icd.csv\nmimiciv/hosp/provider.csv\nmimiciv/hosp/services.csv\nmimiciv/hosp/transfers.csv\nmimiciv/icu/caregiver.csv\nmimiciv/icu/chartevents.csv\nmimiciv/icu/d_items.csv\nmimiciv/icu/datetimeevents.csv\nmimiciv/icu/icustays.csv\nmimiciv/icu/ingredientevents.csv\nmimiciv/icu/inputevents.csv\nmimiciv/icu/outputevents.csv\nmimiciv/icu/procedureevents.csv\nd_items DataFrame head:\n   itemid                    label        abbreviation         linksto  \\\n0  220001             Problem List        Problem List     chartevents   \n1  220003       ICU Admission date  ICU Admission date  datetimeevents   \n2  220045               Heart Rate                  HR     chartevents   \n3  220046  Heart rate Alarm - High     HR Alarm - High     chartevents   \n4  220047   Heart Rate Alarm - Low      HR Alarm - Low     chartevents   \n\n              category unitname     param_type  lownormalvalue  \\\n0              General      NaN           Text             NaN   \n1                  ADT      NaN  Date and time             NaN   \n2  Routine Vital Signs      bpm        Numeric             NaN   \n3               Alarms      bpm        Numeric             NaN   \n4               Alarms      bpm        Numeric             NaN   \n\n   highnormalvalue  \n0              NaN  \n1              NaN  \n2              NaN  \n3              NaN  \n4              NaN  \n---\nAccessing chartevents dataset:\nBlobs in the chartevents container:\nmimiciv/hosp/admissions.csv\nmimiciv/hosp/d_hcpcs.csv\nmimiciv/hosp/d_icd_diagnoses.csv\nmimiciv/hosp/d_icd_procedures.csv\nmimiciv/hosp/d_labitems.csv\nmimiciv/hosp/diagnoses_icd.csv\nmimiciv/hosp/drgcodes.csv\nmimiciv/hosp/emar.csv\nmimiciv/hosp/emar_detail.csv\nmimiciv/hosp/hcpcsevents.csv\nmimiciv/hosp/labevents.csv\nmimiciv/hosp/microbiologyevents.csv\nmimiciv/hosp/omr.csv\nmimiciv/hosp/patients.csv\nmimiciv/hosp/pharmacy.csv\nmimiciv/hosp/poe.csv\nmimiciv/hosp/poe_detail.csv\nmimiciv/hosp/prescriptions.csv\nmimiciv/hosp/procedures_icd.csv\nmimiciv/hosp/provider.csv\nmimiciv/hosp/services.csv\nmimiciv/hosp/transfers.csv\nmimiciv/icu/caregiver.csv\nmimiciv/icu/chartevents.csv\nmimiciv/icu/d_items.csv\nmimiciv/icu/datetimeevents.csv\nmimiciv/icu/icustays.csv\nmimiciv/icu/ingredientevents.csv\nmimiciv/icu/inputevents.csv\nmimiciv/icu/outputevents.csv\nmimiciv/icu/procedureevents.csv\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1713022763587
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dfs['d_items'].head()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1713022463110
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dfs['chartevents'].head()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming chartevents and d_items are already loaded as pandas DataFrames\n",
        "chartevents = chartevents.merge(d_items[['itemid', 'label', 'abbreviation', 'linksto', 'category', 'unitname']], on='itemid', how='left')\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "-- Define the SQL query\n",
        "WITH FilteredJoin AS (\n",
        "  SELECT\n",
        "    ce.itemid,\n",
        "    ce.value,  -- Assuming you want to keep some columns from chartevents\n",
        "    di.label,\n",
        "    di.abbreviation,\n",
        "    di.linksto,\n",
        "    di.category,\n",
        "    di.unitname\n",
        "  FROM\n",
        "    `physionet-data.mimiciv.chartevents` ce\n",
        "  LEFT JOIN\n",
        "    `physionet-data.mimiciv.d_items` di\n",
        "  ON\n",
        "    ce.itemid = di.itemid\n",
        "  WHERE\n",
        "    LOWER(di.label) LIKE '%restraint%'\n",
        ")\n",
        "\n",
        "-- Select unique labels from the filtered join\n",
        "SELECT DISTINCT label\n",
        "FROM FilteredJoin\n",
        "ORDER BY label;\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}